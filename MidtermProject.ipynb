{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619c6a12",
   "metadata": {},
   "source": [
    "Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9778469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78b8ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "08d1b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#items for dataset 1: Dick's Sporting Goods dataset\n",
    "db1Items = set(['Basketball', 'Basketball Shoes', 'Gatorade Bottle', 'Swim Cap', 'Swim Goggles', 'Running Shoes', 'Golf Balls', 'Golf Shoes', 'Protein Powder', 'Electrolyte Gels'])\n",
    "transactions = [\n",
    "    ['Basketball', 'Basketball Shoes', 'Gatorade Bottle'],\n",
    "    ['Swim Cap', 'Swim Goggles'],\n",
    "    ['Running Shoes', 'Electrolyte Gels', 'Gatorade Bottle'],\n",
    "    ['Golf Balls', 'Golf Shoes'],\n",
    "    ['Protein Powder', 'Electrolyte Gels'],\n",
    "    ['Basketball', 'Gatorade Bottle'],\n",
    "    ['Running Shoes', 'Gatorade Bottle'],\n",
    "    ['Swim Cap', 'Swim Goggles'],\n",
    "    ['Swim Cap', 'Gatorade Bottle'],\n",
    "    ['Swim Goggles', 'Gatorade Bottle'],\n",
    "    ['Basketball Shoes', 'Gatorade Bottle'],\n",
    "    ['Golf Shoes', 'Golf Balls'],\n",
    "    ['Running Shoes', 'Protein Powder', 'Electrolyte Gels'],\n",
    "    ['Basketball', 'Basketball Shoes'],\n",
    "    ['Running Shoes', 'Electrolyte Gels'],\n",
    "    ['Swim Cap', 'Swim Goggles', 'Gatorade Bottle'],\n",
    "    ['Golf Shoes', 'Golf Balls'],\n",
    "    ['Protein Powder', 'Gatorade Bottle'],\n",
    "    ['Basketball', 'Protein Powder'],\n",
    "    ['Running Shoes', 'Electrolyte Gels'],\n",
    "    ['Basketball', 'Basketball Shoes', 'Gatorade Bottle'],\n",
    "    ['Running Shoes', 'Electrolyte Gels'],\n",
    "    ['Swim Cap', 'Swim Goggles'],\n",
    "    ['Golf Balls', 'Golf Shoes'],\n",
    "    ['Basketball Shoes', 'Gatorade Bottle'],\n",
    "    ['Running Shoes', 'Gatorade Bottle', 'Protein Powder'],\n",
    "    ['Protein Powder', 'Electrolyte Gels'],\n",
    "    ['Swim Goggles', 'Gatorade Bottle'],\n",
    "    ['Basketball', 'Basketball Shoes'],\n",
    "    ['Running Shoes', 'Electrolyte Gels', 'Gatorade Bottle'],\n",
    "    ['Swim Cap', 'Gatorade Bottle'],\n",
    "    ['Basketball', 'Gatorade Bottle'],\n",
    "    ['Golf Shoes', 'Golf Balls'],\n",
    "    ['Running Shoes', 'Protein Powder'],\n",
    "    ['Basketball', 'Protein Powder', 'Gatorade Bottle'],\n",
    "    ['Swim Cap', 'Swim Goggles', 'Gatorade Bottle'],\n",
    "    ['Running Shoes', 'Electrolyte Gels', 'Gatorade Bottle'],\n",
    "    ['Basketball Shoes', 'Gatorade Bottle'],\n",
    "    ['Golf Balls', 'Golf Shoes'],\n",
    "    ['Running Shoes', 'Electrolyte Gels'],\n",
    "    ['Protein Powder', 'Gatorade Bottle'],\n",
    "    ['Swim Goggles', 'Gatorade Bottle'],\n",
    "    ['Basketball', 'Basketball Shoes'],\n",
    "    ['Running Shoes', 'Electrolyte Gels', 'Protein Powder'],\n",
    "    ['Golf Shoes', 'Golf Balls'],\n",
    "    ['Basketball', 'Gatorade Bottle'],\n",
    "    ['Swim Cap', 'Swim Goggles'],\n",
    "    ['Protein Powder', 'Electrolyte Gels'],\n",
    "    ['Running Shoes', 'Gatorade Bottle'],\n",
    "    ['Golf Balls', 'Golf Shoes'],\n",
    "    ['Basketball Shoes', 'Gatorade Bottle'],\n",
    "    ['Swim Goggles', 'Gatorade Bottle'],\n",
    "    ['Basketball', 'Basketball Shoes', 'Gatorade Bottle'],\n",
    "    ['Running Shoes', 'Protein Powder'],\n",
    "    ['Swim Cap', 'Gatorade Bottle'],\n",
    "    ['Golf Shoes', 'Golf Balls'],\n",
    "    ['Running Shoes', 'Electrolyte Gels'],\n",
    "    ['Basketball', 'Protein Powder', 'Gatorade Bottle'],\n",
    "    ['Swim Goggles', 'Gatorade Bottle'],\n",
    "    ['Basketball Shoes', 'Gatorade Bottle'],\n",
    "    ['Golf Balls', 'Golf Shoes'],\n",
    "    ['Running Shoes', 'Electrolyte Gels', 'Gatorade Bottle'],\n",
    "    ['Basketball', 'Gatorade Bottle'],\n",
    "    ['Swim Cap', 'Swim Goggles'],\n",
    "    ['Protein Powder', 'Electrolyte Gels'],\n",
    "    ['Golf Shoes', 'Golf Balls'],\n",
    "    ['Running Shoes', 'Gatorade Bottle'],\n",
    "    ['Basketball Shoes', 'Gatorade Bottle']\n",
    "]\n",
    "db1 = pd.DataFrame({'Transaction Number':range(1,len(transactions)+1) , 'Items Bought':transactions})\n",
    "db1.to_csv('DicksSportingGoods.csv', index=False)\n",
    "datasets.append('DicksSportingGoods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7018301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#items for dataset 2: Best Buy\n",
    "db2Items = set(['Speaker', 'Computer Mouse', 'Keyboard', 'Desktop PC', 'Smart Phone', 'TV', 'Smart Phone Charger', 'Refrigerator', 'PlayStation', 'Washing Machine'])\n",
    "transactions = [\n",
    "  ['Smart Phone', 'Smart Phone Charger'],\n",
    "  ['Desktop PC', 'Keyboard', 'Computer Mouse'],\n",
    "  ['PlayStation', 'TV'],\n",
    "  ['Smart Phone', 'Speaker'],\n",
    "  ['TV', 'Speaker'],\n",
    "  ['Washing Machine'],\n",
    "  ['Refrigerator'],\n",
    "  ['Smart Phone'],\n",
    "  ['PlayStation'],\n",
    "  ['Desktop PC', 'TV', 'Speaker'],\n",
    "  ['Smart Phone', 'TV'],\n",
    "  ['PlayStation', 'Speaker'],\n",
    "  ['Desktop PC', 'Keyboard'],\n",
    "  ['Smart Phone Charger'],\n",
    "  ['Computer Mouse'],\n",
    "  ['Desktop PC'],\n",
    "  ['Smart Phone', 'TV', 'Smart Phone Charger'],\n",
    "  ['Washing Machine', 'Refrigerator', 'Smart Phone'],\n",
    "  ['TV'],\n",
    "  ['Smart Phone', 'Smart Phone Charger', 'Computer Mouse']\n",
    "]\n",
    "db2 = pd.DataFrame({'Transaction Number':range(1,21) , 'Items Bought':transactions})\n",
    "db2.to_csv('BestBuy.csv', index=False)\n",
    "datasets.append('BestBuy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef795361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#items for dataset 3: Home Depot\n",
    "db3Items = set(['Nails', 'Hammer', 'Wood', 'Screws', 'Seeds', 'Fertilizer', 'Shovel', 'Lawnmower', 'Oven', 'Lightbulb'])\n",
    "transactions = [\n",
    "  ['Nails', 'Hammer', 'Wood'],\n",
    "  ['Screws', 'Hammer', 'Wood'],\n",
    "  ['Seeds', 'Fertilizer', 'Shovel'],\n",
    "  ['Lawnmower', 'Seeds', 'Fertilizer'],\n",
    "  ['Lightbulb'],\n",
    "  ['Nails', 'Screws', 'Wood'],\n",
    "  ['Hammer', 'Nails'],\n",
    "  ['Shovel', 'Seeds', 'Fertilizer'],\n",
    "  ['Lawnmower'],\n",
    "  ['Screws', 'Hammer'],\n",
    "  ['Lightbulb', 'Hammer'],\n",
    "  ['Seeds', 'Lawnmower'],\n",
    "  ['Oven'],\n",
    "  ['Wood', 'Hammer', 'Nails'],\n",
    "  ['Fertilizer', 'Shovel'],\n",
    "  ['Seeds'],\n",
    "  ['Lightbulb'],\n",
    "  ['Hammer', 'Wood'],\n",
    "  ['Oven'],\n",
    "  ['Lawnmower', 'Fertilizer', 'Seeds']\n",
    "]\n",
    "db3 = pd.DataFrame({'Transaction Number':range(1,21) , 'Items Bought':transactions})\n",
    "db3.to_csv('HomeDepot.csv', index=False)\n",
    "datasets.append('HomeDepot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3fd365db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#items for dataset 4: Staples\n",
    "db4Items = set(['Pencil', 'Pen', 'Notebook', 'Binder', 'Paper', 'Printer', 'Tablet', 'Eraser', 'Stapler', 'Staples'])\n",
    "transactions = [\n",
    "    ['Pencil', 'Notebook'],\n",
    "    ['Pen', 'Notebook'],\n",
    "    ['Binder', 'Paper'],\n",
    "    ['Printer', 'Paper'],\n",
    "    ['Tablet', 'Pen'],\n",
    "    ['Eraser', 'Pencil'],\n",
    "    ['Stapler', 'Staples'],\n",
    "    ['Pen', 'Eraser'],\n",
    "    ['Notebook', 'Binder'],\n",
    "    ['Tablet', 'Notebook'],\n",
    "    ['Pencil', 'Binder'],\n",
    "    ['Printer', 'Notebook'],\n",
    "    ['Paper', 'Printer'],\n",
    "    ['Eraser', 'Notebook'],\n",
    "    ['Stapler', 'Paper'],\n",
    "    ['Pencil', 'Stapler'],\n",
    "    ['Pen', 'Pencil'],\n",
    "    ['Tablet', 'Eraser'],\n",
    "    ['Printer', 'Pen'],\n",
    "    ['Binder', 'Staples']\n",
    "]\n",
    "db4 = pd.DataFrame({'Transaction Number':range(1,21) , 'Items Bought':transactions})\n",
    "db4.to_csv('Staples.csv', index=False)\n",
    "datasets.append('Staples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11f2d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#items for dataset 5: GameStop\n",
    "db5Items = set(['Guitar Hero', 'Guitar Hero Guitar', 'PlayStation Controller', 'PlayStation', 'Xbox Controller', 'Xbox', 'Uncharted 4', 'NBA 2k25', 'Halo 4', 'Smash Ultimate'])\n",
    "transactions = [\n",
    "    ['Guitar Hero', 'Guitar Hero Guitar'],\n",
    "    ['PlayStation', 'PlayStation Controller'],\n",
    "    ['Xbox', 'Xbox Controller'],\n",
    "    ['Uncharted 4'],\n",
    "    ['NBA 2k25'],\n",
    "    ['Halo 4'],\n",
    "    ['Smash Ultimate'],\n",
    "    ['PlayStation'],\n",
    "    ['Guitar Hero Guitar', 'Guitar Hero'],\n",
    "    ['PlayStation', 'NBA 2k25'],\n",
    "    ['PlayStation', 'Uncharted 4'],\n",
    "    ['Xbox', 'Halo 4'],\n",
    "    ['Xbox Controller', 'Halo 4'],\n",
    "    ['PlayStation Controller', 'NBA 2k25'],\n",
    "    ['Smash Ultimate'],\n",
    "    ['Guitar Hero', 'Smash Ultimate'],\n",
    "    ['PlayStation Controller', 'Uncharted 4'],\n",
    "    ['Xbox', 'Xbox Controller'],\n",
    "    ['PlayStation Controller'],\n",
    "    ['Halo 4', 'Xbox Controller']\n",
    "]\n",
    "db5 = pd.DataFrame({'Transaction Number':range(1,21) , 'Items Bought':transactions})\n",
    "db5.to_csv('GameStop.csv', index=False)\n",
    "datasets.append('GameStop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50996af",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f4cba9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cfe06a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFrequentItemsets(transactions, itemsets, minSupport):\n",
    "    frequentItemsets = {}\n",
    "    for itemset in itemsets.keys():\n",
    "            # counts the number of times that the itemset can be found in the transactions array\n",
    "            for transaction in transactions:\n",
    "                if isinstance(itemset, str):\n",
    "                    if itemset in set(transaction):\n",
    "                        itemsets[itemset] += 1\n",
    "                elif set(itemset).issubset(set(transaction)):\n",
    "                    itemsets[itemset] += 1\n",
    "            # check to see if it is frequent or not. if it is then add the itemset to the frequent sets array\n",
    "            support = itemsets[itemset]/len(transactions)\n",
    "            if support >= minSupport:\n",
    "                frequentItemsets[itemset] = support\n",
    "    return frequentItemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e9220feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssociationRule:\n",
    "    def __init__(self, a, b, confidence):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.confidence = confidence\n",
    "    def __str__(self):\n",
    "        retstr = ''\n",
    "        if len(self.a)==1:\n",
    "            retstr+=self.a[0]\n",
    "        else:\n",
    "            retstr+=str(self.a)\n",
    "        retstr += \" implies \"\n",
    "        if len(self.b)==1:\n",
    "            retstr+=self.b[0]\n",
    "        else:\n",
    "            retstr+=str(self.b)\n",
    "        retstr+=f' with {self.confidence} confidence'\n",
    "        return retstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "801ce336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAssociationRules(frequentItemsets, minConfidence):\n",
    "    associationRules = set()\n",
    "    for itemSet in frequentItemsets.keys():\n",
    "        if not isinstance(itemSet, str):\n",
    "            sets = []\n",
    "            for i in range(1, len(itemSet)):\n",
    "                sets.extend(list(itertools.combinations(itemSet, i)))\n",
    "            for s in sets:\n",
    "                confidence = 0\n",
    "                if len(s)==1:\n",
    "                    confidence = frequentItemsets[itemSet]/frequentItemsets[s[0]]\n",
    "                else:\n",
    "                    confidence = frequentItemsets[itemSet]/frequentItemsets[s]\n",
    "                if confidence >= minConfidence:\n",
    "                    associationRules.add(AssociationRule(s, tuple(set(itemSet)-set(list(s))), confidence))\n",
    "    return associationRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3f5c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions should be a 2 dimensional array of all the transactions\n",
    "# min support and min confidence should be as a decimal, not a percentage\n",
    "def bruteForce(transactions, minSupport, minConfidence):\n",
    "    frequentSets = {}\n",
    "    items = set()\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            items.add(item)\n",
    "    k = 1\n",
    "    itemsets = {item: 0 for item in items}\n",
    "    while True:\n",
    "        f = findFrequentItemsets(transactions, itemsets, minSupport)\n",
    "        if len(f.keys()) == 0:\n",
    "            break\n",
    "        frequentSets.update(f)\n",
    "        k+=1\n",
    "        itemsets = {item: 0 for item in set(itertools.combinations(items, k))}\n",
    "    return generateAssociationRules(frequentSets, minConfidence)\n",
    "    # do the confidence equations for all the combinations and return the association rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49431a",
   "metadata": {},
   "source": [
    "Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "db66e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0dd66b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) DicksSportingGoods\n",
      "(2) BestBuy\n",
      "(3) HomeDepot\n",
      "(4) Staples\n",
      "(5) GameStop\n",
      "(6) DicksSportingGoods\n",
      "Choose a number corresponding to a dataset: 1\n",
      "Enter a minimum support between 0 and 1: 0.1\n",
      "Enter a minimum confidence between 0 and 1: 0.25\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(datasets)):\n",
    "    print(f'({i+1}) {datasets[i][:-4]}')\n",
    "d=8\n",
    "while d>5 or d<1:\n",
    "    d = int(input('Choose a number corresponding to a dataset: '))\n",
    "file_path = f'./{datasets[d-1]}'\n",
    "minimumSupport = 100\n",
    "while minimumSupport>1 or minimumSupport<0:\n",
    "    minimumSupport = float(input('Enter a minimum support between 0 and 1: '))\n",
    "minimumConfidence = 100\n",
    "while minimumConfidence>1 or minimumConfidence<0:\n",
    "    minimumConfidence = float(input('Enter a minimum confidence between 0 and 1: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fcffd6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "transactions = df['Items Bought'].apply(ast.literal_eval).tolist()\n",
    "rules = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8c6e0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapperFunction(func):\n",
    "    global rules\n",
    "    if func==1:\n",
    "        rules = bruteForce(transactions, minimumSupport, minimumConfidence)\n",
    "    elif func==2:\n",
    "        frequentItemsets = apriori(formattedData, min_support=minimumSupport, use_colnames=True)\n",
    "        rules = association_rules(frequentItemsets, metric=\"confidence\", min_threshold=minimumConfidence)\n",
    "    elif func==3:\n",
    "        frequentItemsets = fpgrowth(formattedData, min_support=minimumSupport, use_colnames=True)\n",
    "        rules = association_rules(frequentItemsets, metric=\"confidence\", min_threshold=minimumConfidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aa16fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swim Goggles implies Gatorade Bottle with 0.5833333333333333 confidence\n",
      "Swim Goggles implies Swim Cap with 0.5833333333333333 confidence\n",
      "Electrolyte Gels implies Running Shoes with 0.7333333333333334 confidence\n",
      "Gatorade Bottle implies Basketball Shoes with 0.2571428571428572 confidence\n",
      "Basketball implies Gatorade Bottle with 0.6923076923076924 confidence\n",
      "Golf Shoes implies Golf Balls with 1.0 confidence\n",
      "Golf Balls implies Golf Shoes with 1.0 confidence\n",
      "Running Shoes implies Gatorade Bottle with 0.47058823529411764 confidence\n",
      "Running Shoes implies Electrolyte Gels with 0.6470588235294118 confidence\n",
      "Gatorade Bottle implies Basketball with 0.2571428571428572 confidence\n",
      "Basketball Shoes implies Gatorade Bottle with 0.75 confidence\n",
      "Swim Cap implies Swim Goggles with 0.7 confidence\n",
      "\n",
      "Execution Time: 0.005120219982927665\n"
     ]
    }
   ],
   "source": [
    "args = tuple([1])\n",
    "executionTime = timeit.timeit(lambda: wrapperFunction(*args), number=1)\n",
    "for rule in rules:\n",
    "    print(rule)\n",
    "print(f'\\nExecution Time: {executionTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1752c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransactionEncoder()\n",
    "formattedData = pd.DataFrame(encoder.fit(transactions).transform(transactions), columns=encoder.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5ea72a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball implies Gatorade Bottle with 0.6923076923076924 confidence\n",
      "Gatorade Bottle implies Basketball with 0.2571428571428572 confidence\n",
      "Gatorade Bottle implies Basketball Shoes with 0.2571428571428572 confidence\n",
      "Basketball Shoes implies Gatorade Bottle with 0.75 confidence\n",
      "Running Shoes implies Electrolyte Gels with 0.6470588235294118 confidence\n",
      "Electrolyte Gels implies Running Shoes with 0.7333333333333334 confidence\n",
      "Running Shoes implies Gatorade Bottle with 0.47058823529411764 confidence\n",
      "Swim Goggles implies Gatorade Bottle with 0.5833333333333333 confidence\n",
      "Golf Balls implies Golf Shoes with 1.0 confidence\n",
      "Golf Shoes implies Golf Balls with 1.0 confidence\n",
      "Swim Goggles implies Swim Cap with 0.5833333333333333 confidence\n",
      "Swim Cap implies Swim Goggles with 0.7 confidence\n",
      "\n",
      "Execution Time: 0.0068089830165263265\n"
     ]
    }
   ],
   "source": [
    "# calls the Apriori Algorithm and outputs the association rules\n",
    "args = tuple([2])\n",
    "executionTime = timeit.timeit(lambda: wrapperFunction(*args), number=1)\n",
    "for t, rule in rules.iterrows():\n",
    "    printstr = ''\n",
    "    if len(rule['antecedents']) == 1:\n",
    "        printstr += tuple(rule['antecedents'])[0]\n",
    "    else:\n",
    "        printstr += str(tuple(rule['antecedents']))\n",
    "    \n",
    "    printstr += ' implies '\n",
    "    \n",
    "    if len(rule['consequents']) == 1:\n",
    "        printstr += tuple(rule['consequents'])[0]\n",
    "    else:\n",
    "        printstr += str(tuple(rule['consequents']))\n",
    "    printstr += f\" with {rule['confidence']} confidence\"\n",
    "    print(printstr)\n",
    "print(f'\\nExecution Time: {executionTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4447bce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball implies Gatorade Bottle with 0.6923076923076924 confidence\n",
      "Gatorade Bottle implies Basketball with 0.2571428571428572 confidence\n",
      "Gatorade Bottle implies Basketball Shoes with 0.2571428571428572 confidence\n",
      "Basketball Shoes implies Gatorade Bottle with 0.75 confidence\n",
      "Swim Goggles implies Gatorade Bottle with 0.5833333333333333 confidence\n",
      "Swim Goggles implies Swim Cap with 0.5833333333333333 confidence\n",
      "Swim Cap implies Swim Goggles with 0.7 confidence\n",
      "Running Shoes implies Gatorade Bottle with 0.47058823529411764 confidence\n",
      "Running Shoes implies Electrolyte Gels with 0.6470588235294118 confidence\n",
      "Electrolyte Gels implies Running Shoes with 0.7333333333333334 confidence\n",
      "Golf Balls implies Golf Shoes with 1.0 confidence\n",
      "Golf Shoes implies Golf Balls with 1.0 confidence\n",
      "\n",
      "Execution Time: 0.015304775995900854\n"
     ]
    }
   ],
   "source": [
    "args = tuple([3])\n",
    "executionTime = timeit.timeit(lambda: wrapperFunction(*args), number=1)\n",
    "for t, rule in rules.iterrows():\n",
    "    printstr = ''\n",
    "    if len(rule['antecedents']) == 1:\n",
    "        printstr += tuple(rule['antecedents'])[0]\n",
    "    else:\n",
    "        printstr += str(tuple(rule['antecedents']))\n",
    "    \n",
    "    printstr += ' implies '\n",
    "    \n",
    "    if len(rule['consequents']) == 1:\n",
    "        printstr += tuple(rule['consequents'])[0]\n",
    "    else:\n",
    "        printstr += str(tuple(rule['consequents']))\n",
    "    printstr += f\" with {rule['confidence']} confidence\"\n",
    "    print(printstr)\n",
    "print(f'\\nExecution Time: {executionTime}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
